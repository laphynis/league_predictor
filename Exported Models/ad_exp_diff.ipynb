{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pd.set_option('chained_assignment',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cells below, I setting up my data, so that I can train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Ad1  Ad1Summ1  Ad1Summ2  Ad1Keystone  Ad1Xp  Ad1Gold  Ad2  Ad2Summ1  \\\n",
      "0     202         4         7         8128  305.8    222.3   29         7   \n",
      "1      50         3         4         8010  285.7    213.5  202         4   \n",
      "2     236         7         4         8005  235.3    156.7   74        14   \n",
      "3     202         7         4         8128  297.2    316.9  222         4   \n",
      "4      21         7         4         8229  289.1    318.9  145         7   \n",
      "...   ...       ...       ...          ...    ...      ...  ...       ...   \n",
      "9743  202         4         7         8128  331.6    317.6  145         7   \n",
      "9744   21         4         7         8128  288.6    233.7   67         4   \n",
      "9745   15         7         4         8008  267.4    260.0   21         7   \n",
      "9746   21         7         4         8005  289.0    248.5  236         7   \n",
      "9747  523         7         4         8005  275.3    198.2   22         4   \n",
      "\n",
      "      Ad2Summ2  Ad2Keystone  ...  Supp2  Supp2Summ1  Supp2Summ2  \\\n",
      "0            4         8008  ...    555           4           7   \n",
      "1            7         8021  ...     40           4           3   \n",
      "2            4         8214  ...     89          14           4   \n",
      "3            7         8021  ...     50           4          14   \n",
      "4            4         9923  ...     63           4          14   \n",
      "...        ...          ...  ...    ...         ...         ...   \n",
      "9743         4         9923  ...    235          21           4   \n",
      "9744         7         8005  ...    143           3           4   \n",
      "9745         4         8229  ...     99           4           3   \n",
      "9746         4         8005  ...    223           3           4   \n",
      "9747         7         8008  ...    147           3           4   \n",
      "\n",
      "      Supp2Keystone  Supp2Xp  Supp2Gold  AdXpDiff  AdGoldDiff  SuppXpDiff  \\\n",
      "0              9923    278.6      216.1    -115.0      -154.0      -658.0   \n",
      "1              8229    281.5      190.8    -269.0     -1116.0      -452.0   \n",
      "2              8437    247.8      386.0    -599.0     -2144.0     -1222.0   \n",
      "3              8128    316.4      275.2    -459.0       362.0      -193.0   \n",
      "4              8128    250.3      275.6    -169.0      -264.0        -2.0   \n",
      "...             ...      ...        ...       ...         ...         ...   \n",
      "9743           8351    295.0      266.6     396.0      -233.0      -928.0   \n",
      "9744           8214    269.6      140.7     191.0       174.0         7.0   \n",
      "9745           8229    195.7      140.3    -776.0      -508.0       444.0   \n",
      "9746           8465    261.0      250.9     679.0       176.0      -386.0   \n",
      "9747           8214    253.8      201.9    -479.0      -976.0      -416.0   \n",
      "\n",
      "      SuppGoldDiff  \n",
      "0           -401.0  \n",
      "1            -33.0  \n",
      "2          -2365.0  \n",
      "3           -758.0  \n",
      "4           -873.0  \n",
      "...            ...  \n",
      "9743        -567.0  \n",
      "9744         298.0  \n",
      "9745         520.0  \n",
      "9746        -692.0  \n",
      "9747        -505.0  \n",
      "\n",
      "[9748 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "sub_df = file[['Ad1', 'Ad1Summ1', 'Ad1Summ2', 'Ad1Keystone', 'Ad1Xp', 'Ad1Gold',\n",
    "                     'Ad2', 'Ad2Summ1', 'Ad2Summ2', 'Ad2Keystone', 'Ad2Xp', 'Ad2Gold',\n",
    "                     'Supp1', 'Supp1Summ1', 'Supp1Summ2', 'Supp1Keystone', 'Supp1Xp', 'Supp1Gold',\n",
    "                     'Supp2', 'Supp2Summ1', 'Supp2Summ2', 'Supp2Keystone', 'Supp2Xp', 'Supp2Gold']]\n",
    "\n",
    "sub_df['AdXpDiff'] = (sub_df['Ad1Xp'] * 10) - (sub_df['Ad2Xp'] * 10)\n",
    "sub_df['AdGoldDiff'] = (sub_df['Ad1Gold'] * 10) - (sub_df['Ad2Gold'] * 10)\n",
    "sub_df['SuppXpDiff'] = (sub_df['Supp1Xp'] * 10) - (sub_df['Supp2Xp'] * 10)\n",
    "sub_df['SuppGoldDiff'] = (sub_df['Supp1Gold'] * 10) - (sub_df['Supp2Gold'] * 10)\n",
    "\n",
    "print(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sub_df[['Ad1', 'Ad1Summ1', 'Ad1Summ2', 'Ad1Keystone', 'Ad2', 'Ad2Summ1', 'Ad2Summ2', 'Ad2Keystone',\n",
    "           'Supp1', 'Supp1Summ1', 'Supp1Summ2', 'Supp1Keystone', 'Supp2', 'Supp2Summ1', 'Supp2Summ2', 'Supp2Keystone']]\n",
    "\n",
    "ad_df = sub_df[['Ad1', 'Ad1Summ1', 'Ad1Summ2', 'Ad1Keystone', 'Ad2', 'Ad2Summ1', 'Ad2Summ2', 'Ad2Keystone']]\n",
    "\n",
    "ad_xp_diff = sub_df['AdXpDiff']\n",
    "ad_g_diff = sub_df['AdGoldDiff']\n",
    "supp_xp_diff = sub_df['SuppXpDiff']\n",
    "supp_g_diff = sub_df['SuppGoldDiff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that my data is ready to be used, I will be comparing a Decision Tree regressor vs a Random Forest Regressor with no parameters to see which performs better. To test my models, I will be training and testing with splits and evaluating the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad exp diff\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, ad_xp_diff, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_forest = RandomForestRegressor(random_state=0)\n",
    "testing_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=0)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_tree = DecisionTreeRegressor(random_state=0)\n",
    "testing_tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forest = testing_forest.predict(x_test)\n",
    "y_tree = testing_tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE : 935.2691280702388\n",
      "Random Tree MSE : 1343.9165511333865\n"
     ]
    }
   ],
   "source": [
    "forest_mse = mean_squared_error(y_test, y_forest)\n",
    "print('Random Forest MSE : {}'.format(numpy.sqrt(forest_mse)))\n",
    "\n",
    "tree_mse = mean_squared_error(y_test, y_tree)\n",
    "print('Decision Tree MSE : {}'.format(numpy.sqrt(tree_mse)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, it appears that the random forest regressor performs much better than the decision tree regressor for this dataset. Therefore, I will continue using the random forest regressor and will begin to tune the parameters to get better results. I will be tuning the parameters of the model through scikit-learn's CVGridSearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# example of a paramter grid that I would use for CVGridSearch\n",
    "#param_grid = {\n",
    "#    'n_estimators' : [400, 500, 600],\n",
    "#    'max_depth' : [3,4,5,6,7],\n",
    "#    'max_features': ['sqrt', 'auto', 'log2'],\n",
    "#    'max_leaf_nodes': [30, 40, 50],\n",
    "#    'criterion' : ['mse']\n",
    "#}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [410, 420, 430],\n",
    "    'max_depth' : [9, 10],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_leaf_nodes': [50, 60],\n",
    "    'criterion' : ['mse']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=4)]: Done  60 out of  60 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=0), n_jobs=4,\n",
       "             param_grid={'criterion': ['mse'], 'max_depth': [9, 10],\n",
       "                         'max_features': ['sqrt'], 'max_leaf_nodes': [50, 60],\n",
       "                         'n_estimators': [410, 420, 430]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_grid = GridSearchCV(estimator=forest, param_grid=param_grid, cv=5, verbose=1, n_jobs=4)\n",
    "cv_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': 60,\n",
       " 'n_estimators': 430}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, max_features='sqrt', max_leaf_nodes=60,\n",
       "                      n_estimators=430, random_state=0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RandomForestRegressor(n_estimators=cv_grid.best_params_['n_estimators'], max_depth=cv_grid.best_params_['max_depth'], max_leaf_nodes=cv_grid.best_params_['max_leaf_nodes'],\n",
    "                               max_features=cv_grid.best_params_['max_features'], random_state=0)\n",
    "model2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "923.7784235654492"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse2 = mean_squared_error(y_test, y2)\n",
    "rmse = numpy.sqrt(mse2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the parameters for my model, you can see that the model's mean squared error only improved by around 10. There is some improvement from the default random forest regressor when validating with the train and test splits. An MSE of about 566 seems to be the limit as any kind of improvement from hypertuning parameters is an insignificant amount. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of validating with train_test_split, I will try cross validation to see if my validation results would become better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([316839.71577186, 323887.46769241, 342037.31446344, 318803.5858504 ,\n",
       "       318668.43861038])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = -1 * cross_val_score(model2, x, ad_xp_diff,\n",
    "                        cv=5 , scoring=\"neg_mean_squared_error\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569.2515300617989"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.sqrt(sum (scores) / len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the average MSE for each fold in our cross validation and square rooting it, there actually isn't that much of a difference compared to the train_test_split.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
